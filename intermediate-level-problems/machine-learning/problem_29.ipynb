{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a36d3b1-1a8d-478e-8060-6477472e6bd4",
   "metadata": {},
   "source": [
    "# **Problem Statement**  \n",
    "## **29. Implement a basic ANN (Artificial Neural Network) using Keras/TensorFlow.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8eaf4-c67c-4ef9-87dd-a1c242b88a5a",
   "metadata": {},
   "source": [
    "Implement a basic Artificial Neural Network (ANN) using Keras/TensorFlow to perform binary classification on a dataset.\n",
    "\n",
    "The model should:\n",
    "- Use fully connected (Dense) layers\n",
    "- Be trained using backpropagation\n",
    "- Be evaluated using accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b96244-784f-44f1-b72a-e69e054e8b67",
   "metadata": {},
   "source": [
    "### Constraints & Example Inputs/Outputs\n",
    "\n",
    "### Constraints\n",
    "- Numerical input features\n",
    "- Binary output (0 or 1)\n",
    "- Small dataset for demonstration\n",
    "- Activation functions: ReLU, Sigmoid\n",
    "\n",
    "### Example Input:\n",
    "```python\n",
    "X = [[0.1, 0.2],\n",
    "     [0.2, 0.8],\n",
    "     [0.8, 0.2],\n",
    "     [0.9, 0.7]]\n",
    "\n",
    "y = [0, 0, 1, 1]\n",
    "\n",
    "```\n",
    "\n",
    "Expected Output:\n",
    "```python\n",
    "Training Accuracy: ~95%\n",
    "Predictions: [0, 0, 1, 1]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e7cad-ea42-4bb3-a20e-a91cba6d7424",
   "metadata": {},
   "source": [
    "### Solution Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b599f-addb-4686-8425-1f6e6f862acd",
   "metadata": {},
   "source": [
    "**Step 1: Prepare Dataset**\n",
    "- Split features (X) and labels (y)\n",
    "- Normalize input values if needed\n",
    "\n",
    "**Step 2: Build ANN Architecture**\n",
    "- Input layer\n",
    "- One or more hidden layers (ReLU)\n",
    "- Output layer (Sigmoid for binary classification)\n",
    "\n",
    "**Step 3: Compile the Model**\n",
    "- Loss function: Binary Crossentropy\n",
    "- Optimizer: Adam\n",
    "- Metric: Accuracy\n",
    "\n",
    "**Step 4: Train the Model**\n",
    "- Use backpropagation\n",
    "- Adjust weights via gradient descent\n",
    "\n",
    "**Step 5: Evaluate & Predict**\n",
    "- Check accuracy\n",
    "- Generate predictions\n",
    "- Validate correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be931aed-e6ac-4398-a9cc-cd43c98ed91b",
   "metadata": {},
   "source": [
    "### Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed0935a-37f8-4d4e-939f-0b92a3863c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/piai/jupyter_env/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /home/piai/jupyter_env/lib/python3.12/site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/piai/jupyter_env/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/piai/jupyter_env/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/piai/jupyter_env/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/piai/jupyter_env/lib/python3.12/site-packages (from tensorflow) (4.14.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/piai/jupyter_env/lib/python3.12/site-packages (from tensorflow) (1.74.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.13.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/piai/jupyter_env/lib/python3.12/site-packages (from tensorflow) (2.2.6)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/piai/jupyter_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/piai/jupyter_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/piai/jupyter_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/piai/jupyter_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /home/piai/jupyter_env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.2.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in /home/piai/jupyter_env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/piai/jupyter_env/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/piai/jupyter_env/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/piai/jupyter_env/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/piai/jupyter_env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m  \u001b[33m0:00:31\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.13.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, optree, opt_einsum, ml_dtypes, markdown, h5py, google_pasta, gast, absl-py, tensorboard, astunparse, keras, tensorflow\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [tensorflow]0m \u001b[32m19/20\u001b[0m [tensorflow]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.12.19 gast-0.7.0 google_pasta-0.2.0 h5py-3.15.1 keras-3.13.0 libclang-18.1.1 markdown-3.10 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0 werkzeug-3.1.4 wheel-0.45.1 wrapt-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0c8f80-daa9-47b6-8178-8e5111fa41d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 19:45:36.566627: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-05 19:45:36.597725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-05 19:45:37.539427: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/piai/jupyter_env/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57cab10a-c58c-459b-b504-16dc7ee1d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: Brute Force ANN (Conceptual – Single Neuron)\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def single_neuron_predict(X, weights, bias):\n",
    "    return sigmoid(np.dot(X, weights) + bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf0f2f1-8be9-4ed7-9087-5945a6e1f224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64106741])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Run\n",
    "X_sample = np.array([[0.8, 0.6]])\n",
    "weights = np.array([1.2, -0.8])\n",
    "bias = 0.1\n",
    "\n",
    "output = single_neuron_predict(X_sample, weights, bias)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febed86-bc77-49f3-aa50-7adfe033688a",
   "metadata": {},
   "source": [
    "### Alternative Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0f40fa-e3cf-49eb-b872-7290e4cc7f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/jupyter_env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1767622727.916318  243960 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach 2: Optimized ANN Using Keras\n",
    "# Create the Dataset\n",
    "X = np.array([\n",
    "    [0.1, 0.2],\n",
    "    [0.2, 0.8],\n",
    "    [0.8, 0.2],\n",
    "    [0.9, 0.7]\n",
    "])\n",
    "\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "#Build ANN Model\n",
    "model = Sequential([\n",
    "    Dense(8, activation='relu', input_shape=(2,)),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#Compile Model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#Train Model\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=100,\n",
    "    batch_size=2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "#Evaluate Model\n",
    "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
    "accuracy\n",
    "\n",
    "#Predictions\n",
    "pred_probs = model.predict(X)\n",
    "pred_labels = (pred_probs > 0.5).astype(int)\n",
    "\n",
    "pred_labels.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164d9bc-0e3b-4391-892e-51cfd51a887a",
   "metadata": {},
   "source": [
    "### Alternative Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf3ad0-4f06-4697-87d4-8ed734705304",
   "metadata": {},
   "source": [
    "**Brute Force Alternatives**\n",
    "- Single-layer perceptron\n",
    "- Manual gradient descent (only for learning purpose, not good for production)\n",
    "\n",
    "**Optimized / Advanced**\n",
    "- Deeper networks\n",
    "- Dropout\n",
    "- Batch Normalization\n",
    "- PyTorch implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31204571-03a3-42ae-8461-d52da4c9a353",
   "metadata": {},
   "source": [
    "### Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1914f61b-475e-4c5c-937e-9fa0304509ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1 Passed: High Accuracy\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: Accuracy Threshhold\n",
    "assert accuracy > 0.9\n",
    "print(\"Test Case 1 Passed: High Accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b4c24f-96c2-4f83-b874-6b9357a56b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 2 Passed: Prediction Shape OK\n"
     ]
    }
   ],
   "source": [
    "# Test Case 2: Prediction Shape\n",
    "assert pred_labels.shape == (4, 1)\n",
    "print(\"Test Case 2 Passed: Prediction Shape OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98116a72-9f96-4a8f-bd6e-7aa747c416d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 3 Passed: Correct Predictions\n"
     ]
    }
   ],
   "source": [
    "# TTest Case 3: Correct Classification\n",
    "expected = np.array([0, 0, 1, 1])\n",
    "assert np.array_equal(pred_labels.flatten(), expected)\n",
    "print(\"Test Case 3 Passed: Correct Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "528251c6-f00b-4236-b737-3df71ecf1c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Case 4: New Sample Prediction\n",
    "new_sample = np.array([[0.85, 0.65]])\n",
    "new_pred = model.predict(new_sample)\n",
    "new_pred > 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462318bf-672f-4468-9122-070cf70b5af5",
   "metadata": {},
   "source": [
    "## Complexity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff61a2e-affa-44cc-b483-573f9dc9b166",
   "metadata": {},
   "source": [
    "### ANN (Per Epoch)\n",
    "- Time: O(n × d × h)\n",
    "- Space: O(d × h)\n",
    "\n",
    "Where:\n",
    "- n = samples\n",
    "- d = input features\n",
    "- h = hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae9b22-a3fd-4d97-807c-9deb388d03b1",
   "metadata": {},
   "source": [
    "#### Thank You!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

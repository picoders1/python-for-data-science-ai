{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a36d3b1-1a8d-478e-8060-6477472e6bd4",
   "metadata": {},
   "source": [
    "# **Problem Statement**  \n",
    "## **1. Implement linear regression from scratch using NumPy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8eaf4-c67c-4ef9-87dd-a1c242b88a5a",
   "metadata": {},
   "source": [
    "Implement Linear Regression from scratch using Numpy, without using any machine learning libraries (such as scikit-learn).\n",
    "\n",
    "Given a dataset with input features x and target vlues y, the goal is to learn the optimal parameters weights (w) and bias (b) such that the predicted values:\n",
    "\n",
    "y=Xw+b\n",
    "\n",
    "minimize the Mean Squared Error (MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b96244-784f-44f1-b72a-e69e054e8b67",
   "metadata": {},
   "source": [
    "### Constraints & Example Inputs/Outputs\n",
    "\n",
    "- Input features are numeric.\n",
    "- Dataset size: small to medium.\n",
    "- No external ML libraries allowed (NumPy only).\n",
    "- Gradient Descent used for optimization.\n",
    "\n",
    "**Example Input**\n",
    "```python\n",
    "X = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "```\n",
    "\n",
    "**Expected Output**\n",
    "```python\n",
    "Weight ≈ 2\n",
    "Bias ≈ 0\n",
    "Predictions ≈ [2, 4, 6, 8, 10]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e7cad-ea42-4bb3-a20e-a91cba6d7424",
   "metadata": {},
   "source": [
    "### Solution Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b599f-addb-4686-8425-1f6e6f862acd",
   "metadata": {},
   "source": [
    "#### 1. Model \n",
    "\n",
    "**Linear Regression Model:**\n",
    "\n",
    "y=wx+b\n",
    "\n",
    "#### 2. Loss Function\n",
    "\n",
    "**Mean Squared Error:**\n",
    "\n",
    "J(w,b)=1/n​∑(y−y^​)2\n",
    "\n",
    "#### 3. Optimization\n",
    "\n",
    "Use **Gradient Descent:**\n",
    "- Update weights and bias iteratively\n",
    "- Move parameters in the direction of minimum loss\n",
    "\n",
    "#### 4. Gradients \n",
    "\n",
    "∂J/∂w = −2/n​∑x(y−y^​)\n",
    "\n",
    "∂J/∂b = −2/n​∑(y−y^​)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be931aed-e6ac-4398-a9cc-cd43c98ed91b",
   "metadata": {},
   "source": [
    "### Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57cab10a-c58c-459b-b504-16dc7ee1d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach1: Brute Force Approach (Normal Equation)\n",
    "\n",
    "# -- closed-form solution - no iteration \n",
    "import numpy as np\n",
    "\n",
    "def linear_regression_bruteforce(X, y):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Add bias term\n",
    "    X_b = np.c_[np.ones(len(X)), X]\n",
    "\n",
    "    # Normal Equation\n",
    "    theta = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
    "\n",
    "    bias = theta[0]\n",
    "    weights = theta[1:]\n",
    "\n",
    "    return weights, bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febed86-bc77-49f3-aa50-7adfe033688a",
   "metadata": {},
   "source": [
    "### Alternative Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d0f40fa-e3cf-49eb-b872-7290e4cc7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach2: Optimized Approach (Gradient Descent)\n",
    "def linear_regression_gradient_descent(X, y, lr=0.01, epochs=1000):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    n = len(y)\n",
    "\n",
    "    w = 0.0\n",
    "    b = 0.0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        y_pred = w * X + b\n",
    "\n",
    "        dw = (-2/n) * np.sum(X * (y - y_pred))\n",
    "        db = (-2/n) * np.sum(y - y_pred)\n",
    "\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164d9bc-0e3b-4391-892e-51cfd51a887a",
   "metadata": {},
   "source": [
    "### Alternative Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf3ad0-4f06-4697-87d4-8ed734705304",
   "metadata": {},
   "source": [
    "#### 1. Normal Equation (Brute Force)\n",
    "- No iterations required\n",
    "- Time: O(n³)\n",
    "- Fails if matrix is non-invertible\n",
    "\n",
    "#### 2. Gradient Descent (Optimized)\n",
    "- Works for large datasets\n",
    "- Time: O(n × epochs)\n",
    "- Preferred in practice\n",
    "\n",
    "#### 3. Stochastic / Mini-Batch Gradient Descent\n",
    "- Faster convergence on large datasets\n",
    "- Used in real ML systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31204571-03a3-42ae-8461-d52da4c9a353",
   "metadata": {},
   "source": [
    "### Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1914f61b-475e-4c5c-937e-9fa0304509ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute Force -> w: [2.] b: 5.662137425588298e-15\n",
      "Gradient Descent -> w: 1.9951803506719779 b: 0.017400463340610635\n"
     ]
    }
   ],
   "source": [
    "# Test Case1: Perfect Linear Data\n",
    "\n",
    "X = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "\n",
    "w_bf, b_bf = linear_regression_bruteforce(X, y)\n",
    "w_gd, b_gd = linear_regression_gradient_descent(X, y)\n",
    "\n",
    "print(\"Brute Force -> w:\", w_bf, \"b:\", b_bf)\n",
    "print(\"Gradient Descent -> w:\", w_gd, \"b:\", b_gd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fe44321-8a1a-4807-ab39-2a18af84130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: 1.9898525247159426 b: 0.05053243256910116\n"
     ]
    }
   ],
   "source": [
    "# Test Case2: With Noise\n",
    "\n",
    "X = [1, 2, 3, 4, 5]\n",
    "y = [2.1, 3.9, 6.2, 7.8, 10.1]\n",
    "\n",
    "w, b = linear_regression_gradient_descent(X, y, lr=0.01, epochs=2000)\n",
    "print(\"w:\", w, \"b:\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1457e42-7cae-4a5a-8b31-8f14d3e3dd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [11.98964758 13.97950011 15.96935263]\n"
     ]
    }
   ],
   "source": [
    "# Test Case3: Predictions Check\n",
    "\n",
    "X_test = np.array([6, 7, 8])\n",
    "y_pred = w * X_test + b\n",
    "print(\"Predictions:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462318bf-672f-4468-9122-070cf70b5af5",
   "metadata": {},
   "source": [
    "## Complexity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff61a2e-affa-44cc-b483-573f9dc9b166",
   "metadata": {},
   "source": [
    "#### Normal Equation\n",
    "- Time: O(n³)\n",
    "- Space: O(n²)\n",
    "\n",
    "#### Gradient Descent\n",
    "- Time: O(n × epochs)\n",
    "- Space: O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae9b22-a3fd-4d97-807c-9deb388d03b1",
   "metadata": {},
   "source": [
    "#### Thank You!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

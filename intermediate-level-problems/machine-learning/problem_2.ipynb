{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a36d3b1-1a8d-478e-8060-6477472e6bd4",
   "metadata": {},
   "source": [
    "# **Problem Statement**  \n",
    "## **2. Build logistic regression from scratch using gradient descent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8eaf4-c67c-4ef9-87dd-a1c242b88a5a",
   "metadata": {},
   "source": [
    "Implement Logistic Regression from scratch using Gradient Descent, without using machine learning libraries such as scikit-learn.\n",
    "\n",
    "Given a dataset with input features X and binary labels y ∈ {0,1}, learn model parameters (weights and bias) to predict the probability:\n",
    "\n",
    "P(y=1∣x)=σ(wx+b)\n",
    "\n",
    "where σ is the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b96244-784f-44f1-b72a-e69e054e8b67",
   "metadata": {},
   "source": [
    "### Constraints & Example Inputs/Outputs\n",
    "\n",
    "#### Constraints\n",
    "- Binary classification only (0 or 1)\n",
    "- Numeric features\n",
    "- NumPy allowed (no ML libraries)\n",
    "- Dataset size: small to medium\n",
    "\n",
    "Example Input:\n",
    "```python\n",
    "X = [1, 2, 3, 4, 5]\n",
    "y = [0, 0, 0, 1, 1]\n",
    "\n",
    "```\n",
    "\n",
    "Expected Output:\n",
    "```python \n",
    "Predicted Probabilities ≈ [0.1, 0.2, 0.4, 0.7, 0.9]\n",
    "Predicted Labels ≈ [0, 0, 0, 1, 1]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e7cad-ea42-4bb3-a20e-a91cba6d7424",
   "metadata": {},
   "source": [
    "### Solution Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b599f-addb-4686-8425-1f6e6f862acd",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "1. Logistic Regression Uses : y^​=σ(wx+b)\n",
    "\n",
    "2. Sigmoid Function : σ(z)=1/(1+e^−z​)\n",
    "\n",
    "3. Loss Function (Binary Cross-Entropy) : J(w,b)=−1/n​∑[ylog(y^​)+(1−y)log(1−y^​)]\n",
    "\n",
    "4. Gradient Descent Updates :\n",
    " \n",
    "- dw=1/n​X^T(y^​−y)\n",
    "\n",
    "- db=1/n​∑(y^​−y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be931aed-e6ac-4398-a9cc-cd43c98ed91b",
   "metadata": {},
   "source": [
    "### Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cab10a-c58c-459b-b504-16dc7ee1d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach1: Brute Force Logistic Regression (Loop-Based)\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression_bruteforce(X, y, lr=0.01, epochs=1000):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    w = 0.0\n",
    "    b = 0.0\n",
    "    n = len(y)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for i in range(n):\n",
    "            z = w * X[i] + b\n",
    "            y_hat = sigmoid(z)\n",
    "\n",
    "            dw = (y_hat - y[i]) * X[i]\n",
    "            db = (y_hat - y[i])\n",
    "\n",
    "            w -= lr * dw\n",
    "            b -= lr * db\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febed86-bc77-49f3-aa50-7adfe033688a",
   "metadata": {},
   "source": [
    "### Alternative Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0f40fa-e3cf-49eb-b872-7290e4cc7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach2: Optimized Logistic Regression (Vectorized Gradient Descent)\n",
    "def logistic_regression_optimized(X, y, lr=0.01, epochs=2000):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    w = 0.0\n",
    "    b = 0.0\n",
    "    n = len(y)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        z = w * X + b\n",
    "        y_hat = sigmoid(z)\n",
    "\n",
    "        dw = (1/n) * np.dot(X, (y_hat - y))\n",
    "        db = (1/n) * np.sum(y_hat - y)\n",
    "\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164d9bc-0e3b-4391-892e-51cfd51a887a",
   "metadata": {},
   "source": [
    "### Alternative Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf3ad0-4f06-4697-87d4-8ed734705304",
   "metadata": {},
   "source": [
    "### 1. Brute Force Gradient Descent\n",
    "- Explicit loops\n",
    "- Easy to understand\n",
    "- Slow for large datasets\n",
    "\n",
    "### 2. Vectorized Gradient Descent (Best)\n",
    "- Faster convergence\n",
    "- Uses NumPy operations\n",
    "- Used in real ML systems\n",
    "\n",
    "### 3. Newton’s Method\n",
    "- Faster convergence\n",
    "- Requires Hessian computation\n",
    "- Rarely used in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31204571-03a3-42ae-8461-d52da4c9a353",
   "metadata": {},
   "source": [
    "### Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1914f61b-475e-4c5c-937e-9fa0304509ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute Force -> w: 1.2844477843109658 b: -4.1967224839632165\n",
      "Optimized -> w: 0.7535694134124141 b: -2.345627557726103\n"
     ]
    }
   ],
   "source": [
    "# Test Case1: Simple Binary Classification\n",
    "\n",
    "X = [1, 2, 3, 4, 5]\n",
    "y = [0, 0, 0, 1, 1]\n",
    "\n",
    "w_bf, b_bf = logistic_regression_bruteforce(X, y)\n",
    "w_opt, b_opt = logistic_regression_optimized(X, y)\n",
    "\n",
    "print(\"Brute Force -> w:\", w_bf, \"b:\", b_bf)\n",
    "print(\"Optimized -> w:\", w_opt, \"b:\", b_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7c1b9c-69e0-44b2-9e75-b8c831c5ee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probabilities: [0.16909453 0.30185317 0.47878292 0.66120083 0.80568613]\n"
     ]
    }
   ],
   "source": [
    "# Test Case2: Probability Predictions\n",
    "\n",
    "X_test = np.array([1, 2, 3, 4, 5])\n",
    "probs = sigmoid(w_opt * X_test + b_opt)\n",
    "print(\"Predicted Probabilities:\", probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f2850b-78f7-4c1b-9be4-b9afefc5d525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: [0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Test Case 3: Class Predictions\n",
    "\n",
    "pred_labels = (probs >= 0.5).astype(int)\n",
    "print(\"Predicted Labels:\", pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c89ec9-009d-45a8-8add-84247ef3c392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: 1.0826363708491005 b: -7.351777164625005\n"
     ]
    }
   ],
   "source": [
    "# Test Case 4: Linearly Separable Data\n",
    "\n",
    "X = [2, 4, 6, 8, 10]\n",
    "y = [0, 0, 0, 1, 1]\n",
    "\n",
    "w, b = logistic_regression_optimized(X, y, lr=0.05, epochs=3000)\n",
    "print(\"w:\", w, \"b:\", b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462318bf-672f-4468-9122-070cf70b5af5",
   "metadata": {},
   "source": [
    "## Complexity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff61a2e-affa-44cc-b483-573f9dc9b166",
   "metadata": {},
   "source": [
    "### Brute Force\n",
    "- Time: O(n × epochs)\n",
    "- Space: O(1)\n",
    "\n",
    "### Optimized\n",
    "- Time: O(n × epochs)\n",
    "- Space: O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae9b22-a3fd-4d97-807c-9deb388d03b1",
   "metadata": {},
   "source": [
    "#### Thank You!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
